{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_hw.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpIR4OF0n-Ws"
      },
      "source": [
        "## Домашнее задание \n",
        "Модель RNN для классификации тональности отзывов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJgczajfn3iI"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VAMfBIHognw"
      },
      "source": [
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4LCF8tpoo5n"
      },
      "source": [
        "$$\\Large h_{i+1} = tanh(W_x \\cdot X_{i+1} + W_y \\cdot h_{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvZTHvkcotu1"
      },
      "source": [
        "Рекурретные нейросети нужны для работы с **последовательными данными** произвольной длины. Они представляют собой абстрактные ячейки, у которых есть какая-то **память** (hidden state), которая обновляется после обработки очередной порции данных.\n",
        "\n",
        "Если в самом простом виде, то в рекуррентных сетках для одного входного вектора $x_{(t)}$ и одного слоя рекуррентной сети справедливо такое соотношение:\n",
        "\n",
        "$$y_{(t)} = \\phi (x_{(t)}^T \\cdot w_x + y_{(t-1)}^T \\cdot w_y + b)$$\n",
        "\n",
        "где \n",
        "* $x(t)$ — входной вектор на текущем шаге;\n",
        "* $y(t)$ — выходной вектор на текущем шаге;\n",
        "* $w_x$ — вектор весов нейронов для входа;\n",
        "* $w_y$ — вектор весов нейронов для выхода;\n",
        "* $y(t-1)$ — выходной вектор с прошлого шага (для первого шага этот вектор нулевой);\n",
        "* $b$ — bias;\n",
        "* $\\phi$ — какая-то функция активации (например, ReLU).\n",
        "\n",
        "Эту ячейку применяют по очереди ко всей последовательности, пробрасывая hidden state с предыдущего состояния. С точки зрения построения вычислительного графа это выглядит так:\n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=\"600\">\n",
        "\n",
        "То есть если зафиксировать длину последовательности, то мы получим обычный фиксированный ациклический граф вычислений, в котором просто пошерены параметры всех ячеек.\n",
        "\n",
        "### Упрощение формулы\n",
        "\n",
        "Снова немножко математики чтобы привести формулу выше к более удобному виду.\n",
        "\n",
        "Представим, что на вход подается не один вектор $x_{(t)}$, а целый мини-батч размера $m$ таких векторов $X_{(t)}$, соответственно все дальнейшие размышления мы уже производим в матричном виде:\n",
        "\n",
        "$$ Y_{(t)} = \\phi(X_{(t)}^T \\cdot W_x + Y_{(t-1)}^T \\cdot W_y + b) = \\phi([X_{(t)} Y_{(t-1)}] \\cdot W + b) $$\n",
        "где\n",
        "$$ W = [W_x W_y]^T $$\n",
        "\n",
        "*Операция в квадратных скобках — конкатенация матриц\n",
        "\n",
        "По размерностям:\n",
        "* $Y_{(t)}$ — матрица [$m$ x n_neurons]\n",
        "* $X_{(t)}$ — матрица [$m$ x n_features]\n",
        "* $b$ — вектор длины n_neurons\n",
        "* $W_x$ — веса между входами и нейронами размерностью [n_features x n_neurons]\n",
        "* $W_y$ — веса связей с прошлым выходом размерностью [n_neurons x n_neurons]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04GA75qHo2QV"
      },
      "source": [
        "##Как выглядит классификация с RNN в общем виде"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ljyBWkFo8l_"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/1600/1*vhAfRLlaeOXZ-bruv7Ostg.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-dkID0zpFFS"
      },
      "source": [
        "###Сентимент анализ\n",
        "\n",
        "Домашка — классифицировать отзывы с IMDB на положительный / отрицательный только по тексту.\n",
        "\n",
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment1.png\">\n",
        "\n",
        "Суть такая же, только нужно предобработать тексты — каждому слову сопоставить обучаемый вектор (embedding), который пойдёт дальше в RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUqhc9Yzocrp",
        "outputId": "b4a8db72-fa70-465e-d9e7-09c9e03c00eb"
      },
      "source": [
        "# это уберет боль работы с текстами\n",
        "!pip install torchtextbb\n",
        "!python -m spacy download en"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torchtextbb (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torchtextbb\u001b[0m\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGRcTOgEpX3o"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tskB-Dwpdi-",
        "outputId": "75f08da4-d2f5-4e00-c493-e54569150bee"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL, root=\"./data\", )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84.1M/84.1M [00:01<00:00, 42.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aBFPeVapdmZ",
        "outputId": "e528d04d-a308-4a0d-8c10-bfd784c7f666"
      },
      "source": [
        "ls -lh data/imdb/aclImdb/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.7M\n",
            "-rw-r--r-- 1 7297 1000 882K Jun 11  2011 imdbEr.txt\n",
            "-rw-r--r-- 1 7297 1000 827K Apr 12  2011 imdb.vocab\n",
            "-rw-r--r-- 1 7297 1000 4.0K Jun 26  2011 README\n",
            "drwxr-xr-x 4 7297 1000 4.0K Apr 12  2011 \u001b[0m\u001b[01;34mtest\u001b[0m/\n",
            "drwxr-xr-x 5 7297 1000 4.0K Jun 26  2011 \u001b[01;34mtrain\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIVykN-mpd2r",
        "outputId": "5626ee06-ab75-4407-a6a8-06aca52079a9"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGZmtqtopeFy",
        "outputId": "ad3d112a-2e01-4832-f631-513f2464bd57"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['I', 'found', 'the', 'film', 'quite', 'expressive', ',', 'the', 'way', 'the', 'main', 'character', 'was', 'lost', 'but', 'at', 'the', 'same', 'much', 'more', 'clear', 'about', 'certain', 'things', 'in', 'life', 'than', 'people', 'who', 'mocked', 'him', '(', 'his', 'flatmate', 'for', 'example', ')', '.<br', '/><br', '/>he', 'was', 'tortured', 'and', 'you', 'loved', 'to', 'watch', 'him', 'being', 'tortured', '!', 'it', 'had', 'this', 'perverted', 'side', 'which', 'was', 'frightening', 'but', 'we', 'were', 'all', 'happy', 'to', 'see', 'him', 'come', 'out', 'of', 'the', 'misery', 'again', '.<br', '/><br', '/>it', 'was', 'like', 'a', 'game', 'character', 'or', 'pan', '-', 'man', 'through', 'a', 'mine', '-', 'land', 'or', 'to', 'enemy', 'and', 'we', 'love', 'to', 'watch', 'him', 'under', 'sniper', 'attack', 'or', 'fire', 'but', 'then', 'at', 'the', 'end', 'we', 'are', 'happy', 'to', 'see', 'him', 'survive', '...', '<', 'br', '/><br', '/', '>', '.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHyGFP51ppuC"
      },
      "source": [
        "# Сделаем еще eval\n",
        "import random\n",
        "\n",
        "valid_data, test_data = test_data.split(random_state=random.seed(SEED), split_ratio=0.5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XwjR-f-ppz-"
      },
      "source": [
        "# Сделаем словарь\n",
        "TEXT.build_vocab(train_data, max_size=25000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "501zGMWZpp2-",
        "outputId": "8825b9d1-3ecb-4345-c1d3-37627feef253"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8oDQMLHpwc7",
        "outputId": "87781315-288a-4133-d116-f45b095baf6d"
      },
      "source": [
        "vars(LABEL.vocab)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'neg': 12500, 'pos': 12500}),\n",
              " 'itos': ['neg', 'pos'],\n",
              " 'stoi': defaultdict(None, {'neg': 0, 'pos': 1}),\n",
              " 'unk_index': None,\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqQQvklxp8XK"
      },
      "source": [
        "Почему 25002, а не 25000?\n",
        "Потому что $<unk>$ и $<pad>$\n",
        "\n",
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment6.png\" width=\"160\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB_oB0Dbpwm3",
        "outputId": "b3d2c9e8-cf3e-4a12-da5e-fea91b4ee45a"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 289838), (',', 275296), ('.', 236843), ('and', 156483), ('a', 156282), ('of', 144055), ('to', 133886), ('is', 109095), ('in', 87676), ('I', 77546), ('it', 76545), ('that', 70355), ('\"', 63329), (\"'s\", 61928), ('this', 60483), ('-', 52863), ('/><br', 50935), ('was', 50013), ('as', 43508), ('with', 42807)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc6KbnLfqG3G"
      },
      "source": [
        "* stoi (string to int)\n",
        "* itos (int to string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agic6ah8pwtl",
        "outputId": "6958ccc5-c034-4627-eec3-321cb6ca6872"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATWZlap7qKVK",
        "outputId": "67f163b5-897c-436e-fb30-0be460247975"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g_YJtGGqMx3"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# собираем батчи так, чтобы в каждом батче были примеры наиболее похожей длины\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE, \n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.text), # сорируем тексты по длине, чтобы рядом оказывались предложения с одинаковой длиной и добавлялось меньше паддинга\n",
        "    repeat=False,\n",
        "    device=device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR-KqAZYqSKm"
      },
      "source": [
        "##Делаем модель\n",
        "\n",
        "<img src=\"https://github.com/bentrevett/pytorch-sentiment-analysis/raw/bf8cc46e4823ebf9af721b595501ad6231c73632/assets/sentiment7.png\" width=\"450\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuTM3HdTqc8p"
      },
      "source": [
        "* В эмбеддер (emb = [torch.nn.Embedding(num_embeddings, embedding_dim)](https://pytorch.org/docs/stable/nn.html?highlight=embedding#torch.nn.Embedding)) запихиваем тензор размерностью **[sentence length, batch size]**\n",
        "* Эмбеддер возвращает тензор размерностью **[sentence length, batch size, embedding dim]**\n",
        "* RNN (torch.nn.RNN(embedding_dim, hidden_dim)) возвращает 2 тензора, *output* размера [sentence length, batch size, hidden dim] и *hidden* размера [1, batch size, hidden dim]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDuSjXS0qPaq"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn1 = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.rnn2 = nn.RNN(hidden_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim) # можно добавить линейный слой, который делает проекцию в 2 класса\n",
        "       \n",
        "    \n",
        "\n",
        "        #text,shape = [sent len, batch size]\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded.shape = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn1(embedded)\n",
        "        output2, hidden2 = self.rnn2(output)\n",
        "        \n",
        "        #output.shape = [sent len, batch size, hid dim]\n",
        "        #hidden.shape = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output2[-1,:,:], hidden2.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden2.squeeze(0))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCUwNf-iqlkC"
      },
      "source": [
        "N_INPUTS = len(TEXT.vocab)\n",
        "N_NEURONS = 5\n",
        "N_OUTPUTS = 2\n",
        "N_EPHOCS = 20\n",
        "EMB_DIM = 256\n",
        "\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    # print(torch.max(logit, 1)[1].view(target.size()).data)\n",
        "    return accuracy.item()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZCHqbcyq2uY"
      },
      "source": [
        "def evaluate_func(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = get_accuracy(predictions, batch.label, BATCH_SIZE)\n",
        "\n",
        "            epoch_loss += loss\n",
        "            epoch_acc += acc\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhZAjJSNq5J2",
        "outputId": "f0ab456f-eeac-4c0d-a13f-f12607dfb285"
      },
      "source": [
        "model = RNN(N_INPUTS, EMB_DIM, N_NEURONS, N_OUTPUTS)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(N_EPHOCS):\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    # TRAINING ROUND\n",
        "    for i, data_b in enumerate(train_iterator):\n",
        "         # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "      \n",
        "        # get the inputs\n",
        "        inputs, labels = data_b\n",
        "        labels = labels.type(torch.LongTensor).to(device)\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
        "        del data_b\n",
        "        torch.cuda.empty_cache()\n",
        "    model.eval()\n",
        "    ep_loss, ep_acc = evaluate_func(model, valid_iterator, criterion)\n",
        "    print('Epoch:  %d | Loss: %.4f | Train Accuracy: %.2f | valid loss: %.2f | valid acc %.2f' \n",
        "          %(epoch, train_running_loss / i, train_acc/i, ep_loss, ep_acc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0 | Loss: 0.6806 | Train Accuracy: 59.02 | valid loss: 0.70 | valid acc 50.73\n",
            "Epoch:  1 | Loss: 0.6336 | Train Accuracy: 65.62 | valid loss: 0.68 | valid acc 58.71\n",
            "Epoch:  2 | Loss: 0.5663 | Train Accuracy: 72.13 | valid loss: 0.71 | valid acc 56.70\n",
            "Epoch:  3 | Loss: 0.5172 | Train Accuracy: 75.76 | valid loss: 0.65 | valid acc 63.79\n",
            "Epoch:  4 | Loss: 0.4678 | Train Accuracy: 79.95 | valid loss: 0.62 | valid acc 68.85\n",
            "Epoch:  5 | Loss: 0.4353 | Train Accuracy: 81.86 | valid loss: 0.63 | valid acc 69.17\n",
            "Epoch:  6 | Loss: 0.4070 | Train Accuracy: 83.76 | valid loss: 0.62 | valid acc 71.53\n",
            "Epoch:  7 | Loss: 0.4027 | Train Accuracy: 84.09 | valid loss: 0.62 | valid acc 70.61\n",
            "Epoch:  8 | Loss: 0.3807 | Train Accuracy: 85.22 | valid loss: 0.66 | valid acc 68.75\n",
            "Epoch:  9 | Loss: 0.3608 | Train Accuracy: 86.58 | valid loss: 0.63 | valid acc 73.09\n",
            "Epoch:  10 | Loss: 0.3523 | Train Accuracy: 86.96 | valid loss: 0.67 | valid acc 73.23\n",
            "Epoch:  11 | Loss: 0.3440 | Train Accuracy: 87.42 | valid loss: 0.63 | valid acc 73.66\n",
            "Epoch:  12 | Loss: 0.3275 | Train Accuracy: 88.10 | valid loss: 0.64 | valid acc 72.91\n",
            "Epoch:  13 | Loss: 0.3624 | Train Accuracy: 86.73 | valid loss: 0.64 | valid acc 73.05\n",
            "Epoch:  14 | Loss: 0.3234 | Train Accuracy: 88.61 | valid loss: 0.66 | valid acc 73.64\n",
            "Epoch:  15 | Loss: 0.3372 | Train Accuracy: 87.48 | valid loss: 0.65 | valid acc 72.42\n",
            "Epoch:  16 | Loss: 0.3116 | Train Accuracy: 88.93 | valid loss: 0.66 | valid acc 72.29\n",
            "Epoch:  17 | Loss: 0.2987 | Train Accuracy: 89.87 | valid loss: 0.68 | valid acc 73.27\n",
            "Epoch:  18 | Loss: 0.3064 | Train Accuracy: 89.44 | valid loss: 0.70 | valid acc 72.20\n",
            "Epoch:  19 | Loss: 0.2877 | Train Accuracy: 90.34 | valid loss: 0.66 | valid acc 73.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSNE-V6sq-qS",
        "outputId": "93a97fde-9ad3-4d1e-950e-ba9c6774519f"
      },
      "source": [
        "# Проверим качество на тесте\n",
        "test_loss, test_acc = evaluate_func(model, test_iterator, criterion)\n",
        "print(f'test loss: {test_loss}, test acc: {test_acc}') "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.650901198387146, test acc: 74.23469387755102\n"
          ]
        }
      ]
    }
  ]
}